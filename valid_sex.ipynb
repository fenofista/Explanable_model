{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3142e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcd66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import torchvision.transforms.functional as tx\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "class AL_Dataset():\n",
    "    def __init__(self, mode):\n",
    "        if(mode==\"train\"):\n",
    "            self.AD_dir = np.array(os.listdir(\"D:/Project/data_crop/training_data/AD\"))\n",
    "            self.CN_dir = np.array(os.listdir(\"D:/Project/data_crop/training_data/CN\"))\n",
    "        else:\n",
    "            self.AD_dir = np.array(os.listdir(\"D:/Project/data_crop/validation_data/AD\"))\n",
    "            self.CN_dir = np.array(os.listdir(\"D:/Project/data_crop/validation_data/CN\"))\n",
    "        self.AD = np.ones((len(self.AD_dir)))\n",
    "        self.CN = np.zeros((len(self.CN_dir)))\n",
    "        self.df = np.concatenate((self.AD_dir, self.CN_dir))\n",
    "        self.label = np.concatenate((self.AD, self.CN))\n",
    "        self.df, self.label = shuffle(self.df, self.label)\n",
    "        self.mode = mode\n",
    "        self.label_df = pd.read_csv(\"../data/B1_correction_new.csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode==\"train\":\n",
    "            if self.label[idx]==1:\n",
    "                image_path = \"D:/Project/data_crop/training_data/AD/\"+self.df[idx]\n",
    "\n",
    "            else:\n",
    "                image_path = \"D:/Project/data_crop/training_data/CN/\"+self.df[idx]\n",
    "\n",
    "        else:\n",
    "            if self.label[idx]==1:\n",
    "                image_path = \"D:/Project/data_crop/validation_data/AD/\"+self.df[idx]\n",
    "\n",
    "            else:\n",
    "                image_path = \"D:/Project/data_crop/validation_data/CN/\"+self.df[idx]\n",
    "#         print(image_path)\n",
    "        patient_ID = image_path.split(\"/\")[5].split(\".\")[0]\n",
    "        index = list(self.label_df[\"Image Data ID\"]).index(patient_ID)\n",
    "        sex = self.label_df[\"Sex\"][index]\n",
    "        if sex ==\"M\":\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        # print(patient_ID)\n",
    "        whole_image = nib.load(image_path)\n",
    "        whole_image = np.array(whole_image.dataobj)\n",
    "        image_arr = np.zeros((90, 256, 256, 3))\n",
    "        for i in range((90)):            \n",
    "            image = whole_image[i]\n",
    "            image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            image = normalize(image)\n",
    "            image = image.reshape(256, 256, 1)\n",
    "            image = np.concatenate((image, image, image), 2)\n",
    "            image_arr[i] = image\n",
    "        return image_arr, label\n",
    "    \n",
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920f3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, writer, epoch, level):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_score = 0\n",
    "    for batch, (X_arr, y) in enumerate(dataloader):\n",
    "        X = X_arr[:,level]\n",
    "        X= torch.moveaxis(X,3,1)\n",
    "        X = X.float()\n",
    "        y = y.long()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        X = X.requires_grad_()\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        total_score += (np.sum(y.cpu().detach().numpy()==np.argmax(pred.cpu().detach().numpy(), axis = 1))/y.shape[0])\n",
    "        loss = loss_fn(pred, y)\n",
    "        total_loss+=(abs(loss)/y.shape[0])\n",
    "        loss.requires_grad_()\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        if batch % 25 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(\"total_loss : \", total_loss)\n",
    "    writer.add_scalar(\"Loss/train\", total_loss/len(dataloader), epoch)\n",
    "    writer.add_scalar(\"Score/train\", total_score/len(dataloader), epoch)\n",
    "    return total_loss, total_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a6a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AL_Dataset(\"train\")\n",
    "val_dataset = AL_Dataset(\"valid\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 1, shuffle = True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size = 1, shuffle = True)\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "weight_map = torch.zeros((2))\n",
    "weight_map[0] = 1\n",
    "weight_map[1] = 1\n",
    "weight_map = weight_map.to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ec234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level :  0 , mean score :  0.571917808219178\n",
      "level :  1 , mean score :  0.5958904109589042\n",
      "level :  2 , mean score :  0.6164383561643836\n",
      "level :  3 , mean score :  0.6095890410958904\n",
      "level :  4 , mean score :  0.6438356164383562\n",
      "level :  5 , mean score :  0.660958904109589\n",
      "level :  6 , mean score :  0.571917808219178\n",
      "level :  7 , mean score :  0.6746575342465754\n",
      "level :  8 , mean score :  0.6712328767123288\n",
      "level :  9 , mean score :  0.6472602739726028\n",
      "level :  10 , mean score :  0.6575342465753424\n",
      "level :  11 , mean score :  0.6575342465753424\n",
      "level :  12 , mean score :  0.6678082191780822\n",
      "level :  13 , mean score :  0.6986301369863014\n",
      "level :  14 , mean score :  0.660958904109589\n",
      "level :  15 , mean score :  0.636986301369863\n",
      "level :  16 , mean score :  0.6335616438356164\n",
      "level :  17 , mean score :  0.702054794520548\n",
      "level :  18 , mean score :  0.6815068493150684\n",
      "level :  19 , mean score :  0.6575342465753424\n",
      "level :  20 , mean score :  0.7123287671232876\n",
      "level :  21 , mean score :  0.7328767123287672\n",
      "level :  22 , mean score :  0.6986301369863014\n",
      "level :  23 , mean score :  0.7671232876712328\n",
      "level :  24 , mean score :  0.75\n",
      "level :  25 , mean score :  0.7157534246575342\n",
      "level :  26 , mean score :  0.7602739726027398\n",
      "level :  27 , mean score :  0.6575342465753424\n",
      "level :  28 , mean score :  0.708904109589041\n",
      "level :  29 , mean score :  0.6917808219178082\n",
      "level :  30 , mean score :  0.7191780821917808\n",
      "level :  31 , mean score :  0.8013698630136986\n",
      "level :  32 , mean score :  0.678082191780822\n",
      "level :  33 , mean score :  0.702054794520548\n",
      "level :  34 , mean score :  0.6198630136986302\n",
      "level :  35 , mean score :  0.7876712328767124\n",
      "level :  36 , mean score :  0.6917808219178082\n",
      "level :  37 , mean score :  0.6575342465753424\n",
      "level :  38 , mean score :  0.6506849315068494\n",
      "level :  39 , mean score :  0.6883561643835616\n",
      "level :  40 , mean score :  0.6575342465753424\n",
      "level :  41 , mean score :  0.7328767123287672\n",
      "level :  42 , mean score :  0.6541095890410958\n",
      "level :  43 , mean score :  0.815068493150685\n",
      "level :  44 , mean score :  0.6678082191780822\n",
      "level :  45 , mean score :  0.75\n",
      "level :  46 , mean score :  0.6472602739726028\n",
      "level :  47 , mean score :  0.6438356164383562\n",
      "level :  48 , mean score :  0.6267123287671232\n",
      "level :  49 , mean score :  0.6952054794520548\n",
      "level :  50 , mean score :  0.6027397260273972\n",
      "level :  51 , mean score :  0.5787671232876712\n",
      "level :  52 , mean score :  0.571917808219178\n",
      "level :  53 , mean score :  0.571917808219178\n",
      "level :  54 , mean score :  0.571917808219178\n",
      "level :  55 , mean score :  0.6506849315068494\n",
      "level :  56 , mean score :  0.6095890410958904\n",
      "level :  57 , mean score :  0.571917808219178\n",
      "level :  58 , mean score :  0.6506849315068494\n",
      "level :  59 , mean score :  0.6643835616438356\n",
      "level :  60 , mean score :  0.6917808219178082\n",
      "level :  61 , mean score :  0.6232876712328768\n",
      "level :  62 , mean score :  0.6575342465753424\n",
      "level :  63 , mean score :  0.6746575342465754\n",
      "level :  64 , mean score :  0.6712328767123288\n",
      "level :  65 , mean score :  0.7226027397260274\n",
      "level :  66 , mean score :  0.6712328767123288\n",
      "level :  67 , mean score :  0.6027397260273972\n",
      "level :  68 , mean score :  0.6506849315068494\n",
      "level :  69 , mean score :  0.5958904109589042\n",
      "level :  70 , mean score :  0.5993150684931506\n",
      "level :  71 , mean score :  0.6404109589041096\n",
      "level :  72 , mean score :  0.636986301369863\n",
      "level :  73 , mean score :  0.6472602739726028\n",
      "level :  74 , mean score :  0.571917808219178\n",
      "level :  75 , mean score :  0.6267123287671232\n",
      "level :  76 , mean score :  0.5993150684931506\n",
      "level :  77 , mean score :  0.571917808219178\n",
      "level :  78 , mean score :  0.5958904109589042\n",
      "level :  79 , mean score :  0.6061643835616438\n",
      "level :  80 , mean score :  0.5753424657534246\n",
      "level :  81 , mean score :  0.571917808219178\n",
      "level :  82 , mean score :  0.571917808219178\n",
      "level :  83 , mean score :  0.5958904109589042\n",
      "level :  84 , mean score :  0.5958904109589042\n",
      "level :  85 , mean score :  0.6438356164383562\n",
      "level :  86 , mean score :  0.6335616438356164\n",
      "level :  87 , mean score :  0.7054794520547946\n",
      "level :  88 , mean score :  0.6335616438356164\n",
      "level :  89 , mean score :  0.6198630136986302\n"
     ]
    }
   ],
   "source": [
    "score_arr=[]\n",
    "for i in range(0,90):\n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(512, 2)\n",
    "    model.load_state_dict(torch.load(\"../data/models_sex/level_\"+str(i)+\"_best.pth\"))\n",
    "    model.to(\"cuda\")\n",
    "    total_score = 0\n",
    "    for batch, (X_arr, y) in enumerate(valid_dataloader):\n",
    "#         if batch%100==0:\n",
    "#             print(batch)\n",
    "        X = X_arr[:,i]\n",
    "        X= torch.moveaxis(X,3,1)\n",
    "        X = X.float()\n",
    "        y = y.long()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        X = X.requires_grad_()\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        total_score += (np.sum(y.cpu().detach().numpy()==np.argmax(pred.cpu().detach().numpy(), axis = 1))/y.shape[0])\n",
    "#         break\n",
    "    score_arr.append(total_score/len(valid_dataloader))\n",
    "    print(\"level : \",i,\", mean score : \", total_score/len(valid_dataloader))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e891b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
